{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of dasc5301-fall2021-p2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevecoffee/dasc5300/blob/main/p2/dasc5301_fall2021_p2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IomjkHgqwz2H"
      },
      "source": [
        "# DASC5301 Data Science, Fall 2021, Chengkai Li, Unversity of Texas at Arlington\n",
        "# Programming Assignment 2\n",
        "# Due: Friday, Octoer 29, 2021, 11:59pm\n",
        "\n",
        "## **Requirements**\n",
        "\n",
        "1.   When you work on this assignment, you should make a copy of this notebook in Google Colab. This can be done using the option `File > Save a copy in Drive` in Google Colab. \n",
        "2.   You should fill in your answer for each task inside the code block right under the task. \n",
        "3.   You should only insert your code into the designated code blocks, as mentioned above. Other than that, you shouldn't change anything else in the notebook.\n",
        "4.   The correct output for each task is also included right below the corresponding code block. \n",
        "5.   Each task can be solved using one line of code. (An exception is Tasks 12, for which it is much easier to use three lines.) Nevertheless, for any task, if you have to use up to three lines, that's fine. But you are not allowed to use more than three lines of code. Note that we have two designated code blocks in both Task 3 and Task 4. \n",
        "6.   You may not use any other imports to solve the tasks. In other words, you shouldn't use `import` in any desinated code blocks for the tasks.\n",
        "7.   You should not use any loops, if statements, or list/dictionary comprehensions. You can solve all the tasks by only using features and functions from pandas. \n",
        "8.   Even if you can only partially solve a task, you should include your code in the code block, which allows us to consider partial credit. \n",
        "9.   However, your code should not raise errors. Any code raising errors will not get partial credit. \n",
        "10.   We tried to minimize the interdependence of the tasks. In most cases, even if you don't solve a task, it won't affect you working on the tasks afterwards, although the output of a task may not be fully correct if you didn't correctly solve the preceding tasks. If you get stuck on a task, you can move on to work on the rest and try to come back to that task later.  \n",
        "11.   To submit your assignment, download your Colab into a .ipynb file. This can be done using the option `Download > Download .ipynb` in Google Colab.\n",
        "12.   Submit the downloaded .ipynb file into the Programming Assignment 2 entry in Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE5MRfJg33ZR"
      },
      "source": [
        "## **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GS0NxL6zpr4"
      },
      "source": [
        "In this assignment, we will do data munging and analysis on a dataset about board games. The dataset is from Kaggle, at https://www.kaggle.com/andrewmvd/board-games. We have already downloaded the CSV file and provided the file in the assignment's entry in canvas. You will need to upload the CSV file to your Google Colab working directory. After that, let's load the CSV file into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V086f30K-dE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "82a09e3e-5dfe-408c-be3c-4ad3246b3f55"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "games = pd.read_csv('https://www.dropbox.com/s/r8cbhijjqrn85d9/bgg_dataset.csv?dl=0', delimiter=';', decimal=\",\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5bb064c89a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.dropbox.com/s/r8cbhijjqrn85d9/bgg_dataset.csv?dl=0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 5, saw 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgPkOZSthw9A"
      },
      "source": [
        "We set `display.max_rows` to `None` for now so that we can see more values in code output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0v6pkCtri0X"
      },
      "source": [
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSq1jdSH98fR"
      },
      "source": [
        "Let's gain some basic understanding of the dataset by using `info()`, `head()`, and `describe()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7wTresvdVWl"
      },
      "source": [
        "games.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vCj7Atyfvjp"
      },
      "source": [
        "games.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0iHZzQvgN3d"
      },
      "source": [
        "games.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfuevEb-a9c"
      },
      "source": [
        "## **Need for data cleaning and preprocessing**\n",
        "\n",
        "The results of these several functions indicate a few needs for cleaning and preprocessing the data:\n",
        "\n",
        "1) The columns `ID`, `Year Published` and `Owned Users` should be integers, but they are floating point numbers.\n",
        "\n",
        "2) There are null values in various columns. \n",
        "\n",
        "3) It seems there could be wrong values. For instance, the minimal value in `Max Players` is 0. What kind of game is that if it allows at most zero player? \n",
        "\n",
        "4) The values in columns `Mechanics` and `Domains` are comma-separated lists. We need to parse these values and get the individual items from the lists.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg9W0E7nGRrF"
      },
      "source": [
        "Let's find out which columns have null values. This could be derived from the `Non-Null Count` in the output of `games.info()`. But there are much simpler ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCZk1EMcw_aB"
      },
      "source": [
        "## **Task 1: For each column, find the number of rows with null value in that column. (5 points)** \n",
        "\n",
        "If your code is correct, its output should tell you that five columns have null values --- column `ID` has missing value in 16 rows, `Year Published` has 1, `Owned Users` has 23, `Mechanics` has 1598, and `Domains` has 10159! Other columns have no null values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vGs8aLSgTB2"
      },
      "source": [
        "# Code for Task 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agWBWQcxzSOO"
      },
      "source": [
        "Since column `ID` has null values, it couldn't be used for uniquely identifying games. Hence, let's take it out. \n",
        "\n",
        "## **Task 2: Remove the `ID` column from the `DataFrame` `games`. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb5JfRdrz3SX"
      },
      "source": [
        "# Code for Task 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYN0cPdIPC56"
      },
      "source": [
        "## **Task 3: Replace null values in column `Year Published` by 5000. Replace null values in column `Owned Users` by -1. Note that this task has two desiganated code blocks. (5 points)** \n",
        "\n",
        "The column `Year Published` has negative values, as `games.descrie()` shows. It actually has 0 in its values too. Hence, we are using a year in the future (5000) to indicate the dataset doesn't provide the value for a game. The column `Owned Users` has 0s too. We thus use -1 to indicate missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhnZsvNfjZRN"
      },
      "source": [
        "# Code for Task 3 : code block for replaceing null values in column Year Published by 5000.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQa9ZyYlQ6Qk"
      },
      "source": [
        "# Code for Task 3: code block for replacing null values in column Owned Users by -1.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODrci3YORMlu"
      },
      "source": [
        "## **Task 4: Convert the data type of column ``Year Pubblished`` to integer. Convert the data type of column ``Owned Users`` to integer too.  Note that this task has two desiganated code blocks. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KueSujDQhuwc"
      },
      "source": [
        "# Code for Task 4: code block for converting the data type of column ``Year Pubblished`` to integer.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXvfJEsaRpnG"
      },
      "source": [
        "# Code for Task 4: code block for converting the data type of column ``Owned Users`` to integer. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y4tZ_UuSSDJ"
      },
      "source": [
        "After you finish Tasks 1 to 4, run `games.info()`, `games.head()`, and `games.describe()` again, to verify you have achieved the goals. In fact, you could do this from time to time, in various places, to make sure you haven't messed up the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6_QVcmKSChW"
      },
      "source": [
        "games.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDVUp8sljtgL"
      },
      "source": [
        "games.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSimeKSdkd0O"
      },
      "source": [
        "games.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHqtanC_ExhJ"
      },
      "source": [
        "Earlier we noticed the existence of value 0 in certain columns which shouldn't have such values. Let's find out how prevalent the prolem is. \n",
        "\n",
        "## **Task 5: For each column, show how many rows have 0 as the value. (5 points)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jERMksm6t7id"
      },
      "source": [
        "# Code for Task 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWqtgUiuoaRc"
      },
      "source": [
        "If you get the correct code, you will see from the output that 46 rows have value 0 in column `Min Players`, 161 in column `Max Players`, 185 in `Year Published`, and so on. We need to keep this mind when we analyze the data so that we don't draw inaccurate conclusions. \n",
        "\n",
        "Particularly, let's examine `Year Published`. We discovered earlier that it also has negative values. We can take a closer look now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLP24wFiAi0W"
      },
      "source": [
        "\n",
        "## **Task 6: Get the number of games published in each year. Sort the years by frequency, in descending order. (10 points)**\n",
        "\n",
        "If you get the code correct, you will find that Year 2017 has 1274 games published, which is the most among all years. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajKIz33BP9ov"
      },
      "source": [
        "# Code for Task 6\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWNGosACsPCl"
      },
      "source": [
        "The oldest game was from 3500 BC. Let's find out which game it is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFfyDh-jDVA5"
      },
      "source": [
        "## **Task 7: Find the name of the oldest game, based on column `Year Published`. (5 points)**\n",
        "\n",
        "If your code is correct, it will return Senet as the name of the oldest game. Some Googling wnd Wikipediaing will verify this game is indeed ancient, although we couldn't verify the accuracy of the exact value -3500. That's fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0koHHa1sk4T"
      },
      "source": [
        "# Code for Task 7\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHvPu_Tptin8"
      },
      "source": [
        "In the output of Task 6, you see that in general the number of games published in a year has been steadily increasing. However, Year 0 appears to be an outlier, as it has 185 games according to the dataset. This doesn't seem right. To further verify, let's do the following Task 8.\n",
        "\n",
        "## **Task 8: Find how many games in total have been publisehd before 1900. Do not include Year 0 in the count. (5 points)**\n",
        "\n",
        "If your code is correct, it shall return 111. We can thus conclude the statistics for Year 0 cannot be correct. Most likely this is because 0 was used to indicate unknown/missing publishing year when the dataset was created. How confusing that is. This reminds us it is important to make good choices in dealing with missing values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lylGsyz_T-2x"
      },
      "source": [
        "# Code for Task 8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PtdcFZaduxG"
      },
      "source": [
        "For the same reason, we believe value 0 in all other columns are not reliable either. Our next task will replace 5000 in `Year Published` and -1 in `Owned Users` by 0. Remember they were actually null values (Task 3). Later we will ignore them together with all 0 values in our analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfdaBcM-htc9"
      },
      "source": [
        "## **Task 9: Replace 5000 in `Year Published` and -1 in `Owned Users` by 0. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-D9yv4kiC8n"
      },
      "source": [
        "# Code for Task 9\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvRA6Z82eZCb"
      },
      "source": [
        "Also, let's take a look at the frequency of each value in column `Min Players`. If you write a piece of code to find out, the code will be similiar to the one in Task 6. Hence, we don't provide it here. Instead, we directly provide the values, as follows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAAPn2IqfZVj"
      },
      "source": [
        "pd.Series({0: 46, 1: 3270, 2: 14076, 3: 2365, 4: 474, 5: 57, 6: 21, 7: 14, 8: 17, 9: 1, 10: 2}, name = 'Min Players')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7uK2MuDgZ9r"
      },
      "source": [
        "Our next task attempts to examine the relationship between `Min Players` and popularity of games measured by ownership. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2O8f0jxgFpj"
      },
      "source": [
        "## **Task 10: For each value of `Min Players`, find the average `Owned Users` for games with the corresponding `Min Players` value. Exclude the games with values 0, 9, 10 in `Min Players` and value 0 in `Owned Users`. (10 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNfCR0UOguEq"
      },
      "source": [
        "As we discussed in Task 8, we don't trust the value 0 in any of the columns. We can thus ignore the games with 0 in `Min Players`. Furthermore, there are only 1 and 2 games for `Min Players` 9 and 10, respectively. The statistics of these games won't be meaningful. When we focus on the rest of the games in the output of Task 10, we will observe a general pattern of decresing ownership by minimum required players. That is probably not surprising, since it is easier to find people to play games with less required players.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwF5yzxzOj2E"
      },
      "source": [
        "# Code for Task 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf6938_4bke_"
      },
      "source": [
        "The pattern from Task 10 appears to have some exceptions, in games with `Min Players` being 5 and 8. Let's take a further look. Before we continue, let's change `display.max_rows` to 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZtYLfr8DYiw"
      },
      "source": [
        "pd.set_option('display.max_rows', 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYBrZ_i8kbIz"
      },
      "source": [
        "## **Task 11: Find the top-5 owned games for each group of games based on `Min Players`. Ideally, you should also exclude the games with values 0, 9, 10 in `Min Players`, like what we did in Task 10. It is fine if you don't do it here. (10 points)**\n",
        "\n",
        "From the output, you see that there are some quite popular games with 5 and 8 `Min Players`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04GlWOrCYdqr"
      },
      "source": [
        "# Code for Task 11 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfLuuyzQ7uTa"
      },
      "source": [
        "## **Task 12: Produce a pivot table using `Rating Average` as the rows (i.e., index) and `Complexity Average` as the columns. The cells of the pivot table should show the number of games having the corresponding rating average and complexity average. Since both `Rating Average` and `Complexity Average` are floating point numbers, we should use bins on both. Let's create ten bins [1,2], (2,3], (3,4], (4,5], (5,6], (6,7], (7,8], (8,9], (9,10] on `Rating Average` and four bins [1,2], (2,3], (3,4], (4,5] on `Complexity Average`. (10 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H-XAOayqd75"
      },
      "source": [
        "The output of `games.describe()` shows that column `Complexity Average` has value 0. Based on our earlier analysis, we shouldn't put much faith in this value. Besides 0, the smallest value in that column is 1. Therefore we decide to have four bins for `Complexity Average`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H9HyGJ7rP27"
      },
      "source": [
        "# Code for Task 12\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZf_7dSnFNbW"
      },
      "source": [
        "The pivot table suggests a positive correlation between these two columns. As the complexity of games increases, the rating also tends to increase. Perhaps this is intuitive. For complex games to have a market, it needs to be of higher quality. \n",
        "\n",
        "In fact, we can directly calculate the correlation using `corr`, as follows. The value of 0.5 in Pearson correlation coefficient suggests a fairly large positive correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enKY8MaiHf-1"
      },
      "source": [
        "g = games[games['Complexity Average']>0]\n",
        "\n",
        "g['Rating Average'].corr(g['Complexity Average'], method='pearson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU3KPGNQ1TdB"
      },
      "source": [
        "In the next task, we are going to produce a similar pivot table, focusing on `Owned Users`. Ideally we want to exclude the games with value 0 on this column. To simplify things, we are not requiring you to do it. The pattern we will be seeing is not changed, since only 23 games would have been removed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wTNr-mlzQJt"
      },
      "source": [
        "## **Task 13: Produce another pivot table using `Rating Average` and `Complexity Average`, with the same binning. However, this time the cells of the pivot table should show average `Owned Users` of games matching the corresponding rating average and complexity average. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3OBpFT3b2mG"
      },
      "source": [
        "# Code for Task 13\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmdYEdxPxHda"
      },
      "source": [
        "If your code is correct, this pivot table also shows some interesting patterns. At every rating tier till (7, 8], simpler games enjoy larger ownerships. However, for the really good games with ratings greater than 8, players are not afraid of their complexity. In fact, the more complex games in this rating tier get owned by more players."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixyje9aBlbYE"
      },
      "source": [
        "Now we will process the `Mechanics` and `Domains` columns. They store values as strings. Each string is a comma-separated list of items. The following code will turn `Mechanics` into a DataFrame itself, with each column corresponding to a unique item from the comma-separated lists. Similarly, we are creating a new DataFrame for the `Domains` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMfogtswzvTZ"
      },
      "source": [
        "mechanics = games['Mechanics'].str.get_dummies(sep=\", \")\n",
        "domains = games['Domains'].str.get_dummies(sep=\", \")\n",
        "\n",
        "mechanics = pd.concat([games['Name'], mechanics], 1)\n",
        "domains = pd.concat([games['Name'], domains], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxrvRoeLnHJq"
      },
      "source": [
        "Let's take a look at the columns in the new DataFrame `mechanics`. The values are 1 and 0, i.e., essentially Boolean, indicating whether a game uses the corresponding mechanics or not. This is also called *one-hot encoding*. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJvbgJKXnviK"
      },
      "source": [
        "mechanics.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmRFSDDnxAZ"
      },
      "source": [
        "Similarly the new DataFrame `domains` uses one-hot encoding to record the games' domain types. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cjYR990n6Kj"
      },
      "source": [
        "domains.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9fdpQOjtKYR"
      },
      "source": [
        "Let's find out which are the most common game domains and which are the least common ones. If your code for the following task is correct, the output should show there are 3316 `Wargames`, the most common type. The least common type is `Customizable Games`, with 297 games. \n",
        "\n",
        "## **Task 14: For each domain, list its frequency, i.e., the number of games belonging to that domain. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX7JMGt6tY-E"
      },
      "source": [
        "# Code for Task 14\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDI50sPJqLds"
      },
      "source": [
        "## **Task 15: Find out the average `Complexity Average` of games that belong to `Wargames`. You should exclude games with 0 on `Complexity Average`. (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38FPNkYdFZKk"
      },
      "source": [
        "# Code for Task 15 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItMSAO8wreQb"
      },
      "source": [
        "If you code is correct, 2.874 is the value. If you perform the same task on `Children's Games`, you will get 1.175. These two are the two types of games with the largest and smallest average `Complexity Average`. If you want to calculate this for every type of games, the following code does it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-DfPwwDH0jR"
      },
      "source": [
        "results = \\\n",
        "    (games[games['Complexity Average']>0].set_index(games.columns.drop('Domains',1).tolist())\n",
        "    .Domains.str.split(', ', expand=True)\n",
        "    .stack()\n",
        "    .reset_index()\n",
        "    .rename(columns={0:'domain'})\n",
        "    .loc[:,['domain','Owned Users', 'Rating Average', 'Complexity Average']]\n",
        "    .groupby('domain').agg({'Owned Users':['mean'], 'Rating Average':['mean'], 'Complexity Average':['mean']})\n",
        "    )\n",
        "results "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}